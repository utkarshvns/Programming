{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Source: https://archive.ics.uci.edu/ml/datasets/Combined+Cycle+Power+Plant\n",
    "\n",
    "Features consist of hourly average ambient variables\n",
    "\n",
    "Temperature (T) in the range 1.81°C and 37.11°C,\n",
    "Ambient Pressure (AP) in the range 992.89-1033.30 milibar,\n",
    "Relative Humidity (RH) in the range 25.56% to 100.16%\n",
    "Exhaust Vacuum (V) in teh range 25.36-81.56 cm Hg\n",
    "Net hourly electrical energy output (EP) 420.26-495.76 MW\n",
    "The averages are taken from various sensors located around the plant that record the ambient variables every second. The variables are given without normalization.\n",
    "\n",
    "Dataset Information:\n",
    "\n",
    "The dataset contains 9568 data points collected from a Combined Cycle Power Plant over 6 years (2006-2011), when the power plant was set to work with full load. Features consist of hourly average ambient variables Temperature (T), Ambient Pressure (AP), Relative Humidity (RH) and Exhaust Vacuum (V) to predict the net hourly electrical energy output (EP) of the plant. \n",
    "A combined cycle power plant (CCPP) is composed of gas turbines (GT), steam turbines (ST) and heat recovery steam generators. In a CCPP, the electricity is generated by gas and steam turbines, which are combined in one cycle, and is transferred from one turbine to another. While the Vacuum is colected from and has effect on the Steam Turbine, he other three of the ambient variables effect the GT performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 345560\r\n",
      "drwxr-xr-x 2 training training      4096 Oct 17  2016 ml-20m\r\n",
      "-rw-r--r-- 1 training training 127744095 Mar 24 20:20 stocks.csv\r\n",
      "drwxrwxrwx 2 training training      4096 Jun 18 21:08 ml-latest-small\r\n",
      "-rw-r--r-- 1 training training 150828752 Sep 13 15:33 creditcard-fraud.csv\r\n",
      "drwxrwxr-x 2 training training      4096 Sep 13 20:35 mnist\r\n",
      "-rw-rw-r-- 1 training training    133638 Sep 13 21:00 credit.csv\r\n",
      "-rw-rw-r-- 1 training training  69055807 Sep 13 21:01 imdb-comments.json\r\n",
      "-rw-rw-r-- 1 training training      5107 Sep 13 21:01 iris.csv\r\n",
      "-rw-rw-r-- 1 training training     57459 Sep 13 21:01 istanbul-stock.csv\r\n",
      "-rw-rw-r-- 1 training training       226 Sep 13 21:01 mobile-sales-data.csv\r\n",
      "-rw-rw-r-- 1 training training      2436 Sep 13 21:01 startups.csv\r\n",
      "drwxrwxr-x 2 training training      4096 Sep 13 21:01 kaggle-house-prices\r\n",
      "-rw-rw-r-- 1 training training   4432265 Sep 13 23:51 Bible.txt\r\n",
      "drwxrwxr-x 2 training training      4096 Sep 15 05:58 apple.stackexchange.com\r\n",
      "-rw-rw-r-- 1 training training   1543413 Sep 15 06:55 Combined_Cycle_Power_Plant.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls -ltr ~/Downloads/datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"csv\").option(\"header\",\"true\")\\\n",
    ".option(\"inferSchema\",\"true\").load(\"/home/training/Downloads/datasets/Combined_Cycle_Power_Plant.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+-------+-----+------+\n",
      "|   AT|    V|     AP|   RH|    PE|\n",
      "+-----+-----+-------+-----+------+\n",
      "|14.96|41.76|1024.07|73.17|463.26|\n",
      "|25.18|62.96|1020.04|59.08|444.37|\n",
      "| 5.11| 39.4|1012.16|92.14|488.56|\n",
      "|20.86|57.32|1010.24|76.64|446.48|\n",
      "|10.82| 37.5|1009.23|96.62| 473.9|\n",
      "|26.27|59.44|1012.23|58.77|443.67|\n",
      "|15.89|43.96|1014.02|75.24|467.35|\n",
      "| 9.48|44.71|1019.12|66.43|478.42|\n",
      "|14.64| 45.0|1021.78|41.25|475.98|\n",
      "|11.74|43.56|1015.14|70.72| 477.5|\n",
      "|17.99|43.72|1008.64|75.04|453.02|\n",
      "|20.14|46.93|1014.66|64.22|453.99|\n",
      "|24.34| 73.5|1011.31|84.15|440.29|\n",
      "|25.71|58.59|1012.77|61.83|451.28|\n",
      "|26.19|69.34|1009.48|87.59|433.99|\n",
      "|21.42|43.79|1015.76|43.08|462.19|\n",
      "|18.21| 45.0|1022.86|48.84|467.54|\n",
      "|11.04|41.74| 1022.6|77.51| 477.2|\n",
      "|14.45|52.75|1023.97|63.59|459.85|\n",
      "|13.97|38.47|1015.15|55.28| 464.3|\n",
      "+-----+-----+-------+-----+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[AT: double, V: double, AP: double, RH: double, PE: double]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Spark Dataframe to Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>V</th>\n",
       "      <th>AP</th>\n",
       "      <th>RH</th>\n",
       "      <th>PE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.96</td>\n",
       "      <td>41.76</td>\n",
       "      <td>1024.07</td>\n",
       "      <td>73.17</td>\n",
       "      <td>463.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.18</td>\n",
       "      <td>62.96</td>\n",
       "      <td>1020.04</td>\n",
       "      <td>59.08</td>\n",
       "      <td>444.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.11</td>\n",
       "      <td>39.40</td>\n",
       "      <td>1012.16</td>\n",
       "      <td>92.14</td>\n",
       "      <td>488.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.86</td>\n",
       "      <td>57.32</td>\n",
       "      <td>1010.24</td>\n",
       "      <td>76.64</td>\n",
       "      <td>446.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.82</td>\n",
       "      <td>37.50</td>\n",
       "      <td>1009.23</td>\n",
       "      <td>96.62</td>\n",
       "      <td>473.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AT      V       AP     RH      PE\n",
       "0  14.96  41.76  1024.07  73.17  463.26\n",
       "1  25.18  62.96  1020.04  59.08  444.37\n",
       "2   5.11  39.40  1012.16  92.14  488.56\n",
       "3  20.86  57.32  1010.24  76.64  446.48\n",
       "4  10.82  37.50  1009.23  96.62  473.90"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.toPandas().head() #Do not run on large dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verctorize the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+-------+-----+------+--------------------+\n",
      "|   AT|    V|     AP|   RH|    PE|            features|\n",
      "+-----+-----+-------+-----+------+--------------------+\n",
      "|14.96|41.76|1024.07|73.17|463.26|[14.96,41.76,1024...|\n",
      "|25.18|62.96|1020.04|59.08|444.37|[25.18,62.96,1020...|\n",
      "| 5.11| 39.4|1012.16|92.14|488.56|[5.11,39.4,1012.1...|\n",
      "|20.86|57.32|1010.24|76.64|446.48|[20.86,57.32,1010...|\n",
      "|10.82| 37.5|1009.23|96.62| 473.9|[10.82,37.5,1009....|\n",
      "|26.27|59.44|1012.23|58.77|443.67|[26.27,59.44,1012...|\n",
      "|15.89|43.96|1014.02|75.24|467.35|[15.89,43.96,1014...|\n",
      "| 9.48|44.71|1019.12|66.43|478.42|[9.48,44.71,1019....|\n",
      "|14.64| 45.0|1021.78|41.25|475.98|[14.64,45.0,1021....|\n",
      "|11.74|43.56|1015.14|70.72| 477.5|[11.74,43.56,1015...|\n",
      "|17.99|43.72|1008.64|75.04|453.02|[17.99,43.72,1008...|\n",
      "|20.14|46.93|1014.66|64.22|453.99|[20.14,46.93,1014...|\n",
      "|24.34| 73.5|1011.31|84.15|440.29|[24.34,73.5,1011....|\n",
      "|25.71|58.59|1012.77|61.83|451.28|[25.71,58.59,1012...|\n",
      "|26.19|69.34|1009.48|87.59|433.99|[26.19,69.34,1009...|\n",
      "|21.42|43.79|1015.76|43.08|462.19|[21.42,43.79,1015...|\n",
      "|18.21| 45.0|1022.86|48.84|467.54|[18.21,45.0,1022....|\n",
      "|11.04|41.74| 1022.6|77.51| 477.2|[11.04,41.74,1022...|\n",
      "|14.45|52.75|1023.97|63.59|459.85|[14.45,52.75,1023...|\n",
      "|13.97|38.47|1015.15|55.28| 464.3|[13.97,38.47,1015...|\n",
      "+-----+-----+-------+-----+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorizer = VectorAssembler()\n",
    "vectorizer.setInputCols([\"AT\", \"V\", \"AP\", \"RH\"])\n",
    "vectorizer.setOutputCol(\"features\")\n",
    "\n",
    "df_vect = vectorizer.transform(df)\n",
    "df_vect.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputCols: input column names. (current: ['AT', 'V', 'AP', 'RH'])\n",
      "outputCol: output column name. (default: VectorAssembler_406dae73f80cb9440a18__output)\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.explainParams())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aggregationDepth: suggested depth for treeAggregate (>= 2). (default: 2)\n",
      "elasticNetParam: the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty. (default: 0.0)\n",
      "featuresCol: features column name. (default: features)\n",
      "fitIntercept: whether to fit an intercept term. (default: True)\n",
      "labelCol: label column name. (default: label)\n",
      "maxIter: max number of iterations (>= 0). (default: 100)\n",
      "predictionCol: prediction column name. (default: prediction)\n",
      "regParam: regularization parameter (>= 0). (default: 0.0)\n",
      "solver: the solver algorithm for optimization. If this is not set or empty, default value is 'auto'. (default: auto)\n",
      "standardization: whether to standardize the training features before fitting the model. (default: True)\n",
      "tol: the convergence tolerance for iterative algorithms (>= 0). (default: 1e-06)\n",
      "weightCol: weight column name. If this is not set or empty, we treat all instance weights as 1.0. (undefined)\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "print(lr.explainParams())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.setLabelCol(\"PE\")\n",
    "lr.setFeaturesCol(\"features\")\n",
    "model = lr.fit(df_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.ml.regression.LinearRegressionModel"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.9286835997167648\n",
      "Intercept:  454.5637357984046 Coefficients [-1.97731604346,-0.234028456499,0.0621277600987,-0.158016554398]\n"
     ]
    }
   ],
   "source": [
    "print(\"R2:\", model.summary.r2)\n",
    "print(\"Intercept: \", model.intercept, \"Coefficients\", model.coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+-------+-----+------+--------------------+------------------+\n",
      "|   AT|    V|     AP|   RH|    PE|            features|        prediction|\n",
      "+-----+-----+-------+-----+------+--------------------+------------------+\n",
      "|14.96|41.76|1024.07|73.17|463.26|[14.96,41.76,1024...| 467.2711634437306|\n",
      "|25.18|62.96|1020.04|59.08|444.37|[25.18,62.96,1020...|444.07766858004396|\n",
      "| 5.11| 39.4|1012.16|92.14|488.56|[5.11,39.4,1012.1...|483.56251796945776|\n",
      "|20.86|57.32|1010.24|76.64|446.48|[20.86,57.32,1010...| 450.5559716382537|\n",
      "|10.82| 37.5|1009.23|96.62| 473.9|[10.82,37.5,1009....| 471.8267489278455|\n",
      "|26.27|59.44|1012.23|58.77|443.67|[26.27,59.44,1012...| 442.3099415850402|\n",
      "|15.89|43.96|1014.02|75.24|467.35|[15.89,43.96,1014...|463.96591866241715|\n",
      "| 9.48|44.71|1019.12|66.43|478.42|[9.48,44.71,1019....| 478.1739705793852|\n",
      "|14.64| 45.0|1021.78|41.25|475.98|[14.64,45.0,1021....|472.04726822434776|\n",
      "|11.74|43.56|1015.14|70.72| 477.5|[11.74,43.56,1015...| 473.0492095425741|\n",
      "|17.99|43.72|1008.64|75.04|453.02|[17.99,43.72,1008...| 459.5670777622559|\n",
      "|20.14|46.93|1014.66|64.22|453.99|[20.14,46.93,1014...|456.64836515783395|\n",
      "|24.34| 73.5|1011.31|84.15|440.29|[24.34,73.5,1011....| 438.7681037606262|\n",
      "|25.71|58.59|1012.77|61.83|451.28|[25.71,58.59,1012...| 443.1661810913976|\n",
      "|26.19|69.34|1009.48|87.59|433.99|[26.19,69.34,1009...| 435.4263567111474|\n",
      "|21.42|43.79|1015.76|43.08|462.19|[21.42,43.79,1015...| 458.2610604716974|\n",
      "|18.21| 45.0|1022.86|48.84|467.54|[18.21,45.0,1022....|463.85600228221267|\n",
      "|11.04|41.74| 1022.6|77.51| 477.2|[11.04,41.74,1022...| 474.2498032497976|\n",
      "|14.45|52.75|1023.97|63.59|459.85|[14.45,52.75,1023...| 467.2152077040968|\n",
      "|13.97|38.47|1015.15|55.28| 464.3|[13.97,38.47,1015...|472.27139648674444|\n",
      "+-----+-----+-------+-----+------+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pred = model.transform(df_vect)\n",
    "df_pred.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labelCol: label column name. (default: label)\n",
      "metricName: metric name in evaluation - one of:\n",
      "                       rmse - root mean squared error (default)\n",
      "                       mse - mean squared error\n",
      "                       r2 - r^2 metric\n",
      "                       mae - mean absolute error. (default: rmse)\n",
      "predictionCol: prediction column name. (default: prediction)\n"
     ]
    }
   ],
   "source": [
    "evaluator = RegressionEvaluator()\n",
    "print(evaluator.explainParams())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.557525128298466"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = RegressionEvaluator(labelCol = \"PE\", predictionCol = \"prediction\", metricName = \"rmse\")\n",
    "evaluator.evaluate(df_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.pipeline import Pipeline, PipelineModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stages: a list of pipeline stages (undefined)\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline()\n",
    "print(pipeline.explainParams())\n",
    "pipeline.setStages([vectorizer, lr])\n",
    "pipelineModel = pipeline.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[VectorAssembler_4fbf8efe8908beb31164, LinearRegression_4bf49d4e37c6cf84ec09]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.getStages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([-1.9773, -0.234, 0.0621, -0.158])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model = pipelineModel.stages[1]\n",
    "lr_model .coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+-------+-----+------+--------------------+------------------+\n",
      "|   AT|    V|     AP|   RH|    PE|            features|        prediction|\n",
      "+-----+-----+-------+-----+------+--------------------+------------------+\n",
      "|14.96|41.76|1024.07|73.17|463.26|[14.96,41.76,1024...| 467.2711634437306|\n",
      "|25.18|62.96|1020.04|59.08|444.37|[25.18,62.96,1020...|444.07766858004396|\n",
      "| 5.11| 39.4|1012.16|92.14|488.56|[5.11,39.4,1012.1...|483.56251796945776|\n",
      "|20.86|57.32|1010.24|76.64|446.48|[20.86,57.32,1010...| 450.5559716382537|\n",
      "|10.82| 37.5|1009.23|96.62| 473.9|[10.82,37.5,1009....| 471.8267489278455|\n",
      "|26.27|59.44|1012.23|58.77|443.67|[26.27,59.44,1012...| 442.3099415850402|\n",
      "|15.89|43.96|1014.02|75.24|467.35|[15.89,43.96,1014...|463.96591866241715|\n",
      "| 9.48|44.71|1019.12|66.43|478.42|[9.48,44.71,1019....| 478.1739705793852|\n",
      "|14.64| 45.0|1021.78|41.25|475.98|[14.64,45.0,1021....|472.04726822434776|\n",
      "|11.74|43.56|1015.14|70.72| 477.5|[11.74,43.56,1015...| 473.0492095425741|\n",
      "|17.99|43.72|1008.64|75.04|453.02|[17.99,43.72,1008...| 459.5670777622559|\n",
      "|20.14|46.93|1014.66|64.22|453.99|[20.14,46.93,1014...|456.64836515783395|\n",
      "|24.34| 73.5|1011.31|84.15|440.29|[24.34,73.5,1011....| 438.7681037606262|\n",
      "|25.71|58.59|1012.77|61.83|451.28|[25.71,58.59,1012...| 443.1661810913976|\n",
      "|26.19|69.34|1009.48|87.59|433.99|[26.19,69.34,1009...| 435.4263567111474|\n",
      "|21.42|43.79|1015.76|43.08|462.19|[21.42,43.79,1015...| 458.2610604716974|\n",
      "|18.21| 45.0|1022.86|48.84|467.54|[18.21,45.0,1022....|463.85600228221267|\n",
      "|11.04|41.74| 1022.6|77.51| 477.2|[11.04,41.74,1022...| 474.2498032497976|\n",
      "|14.45|52.75|1023.97|63.59|459.85|[14.45,52.75,1023...| 467.2152077040968|\n",
      "|13.97|38.47|1015.15|55.28| 464.3|[13.97,38.47,1015...|472.27139648674444|\n",
      "+-----+-----+-------+-----+------+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipelineModel.transform(df).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.557525128298466"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate(pipelineModel.transform(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the pipeline to disk to persist the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelineModel.save(\"lr-pipeline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the persisted model from the disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([-1.9773, -0.234, 0.0621, -0.158])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_model = PipelineModel.load(\"lr-pipeline\")\n",
    "saved_model.stages[1].coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+-------+-----+------+--------------------+------------------+\n",
      "|   AT|    V|     AP|   RH|    PE|            features|        prediction|\n",
      "+-----+-----+-------+-----+------+--------------------+------------------+\n",
      "|14.96|41.76|1024.07|73.17|463.26|[14.96,41.76,1024...| 467.2711634437306|\n",
      "|25.18|62.96|1020.04|59.08|444.37|[25.18,62.96,1020...|444.07766858004396|\n",
      "| 5.11| 39.4|1012.16|92.14|488.56|[5.11,39.4,1012.1...|483.56251796945776|\n",
      "|20.86|57.32|1010.24|76.64|446.48|[20.86,57.32,1010...| 450.5559716382537|\n",
      "|10.82| 37.5|1009.23|96.62| 473.9|[10.82,37.5,1009....| 471.8267489278455|\n",
      "|26.27|59.44|1012.23|58.77|443.67|[26.27,59.44,1012...| 442.3099415850402|\n",
      "|15.89|43.96|1014.02|75.24|467.35|[15.89,43.96,1014...|463.96591866241715|\n",
      "| 9.48|44.71|1019.12|66.43|478.42|[9.48,44.71,1019....| 478.1739705793852|\n",
      "|14.64| 45.0|1021.78|41.25|475.98|[14.64,45.0,1021....|472.04726822434776|\n",
      "|11.74|43.56|1015.14|70.72| 477.5|[11.74,43.56,1015...| 473.0492095425741|\n",
      "|17.99|43.72|1008.64|75.04|453.02|[17.99,43.72,1008...| 459.5670777622559|\n",
      "|20.14|46.93|1014.66|64.22|453.99|[20.14,46.93,1014...|456.64836515783395|\n",
      "|24.34| 73.5|1011.31|84.15|440.29|[24.34,73.5,1011....| 438.7681037606262|\n",
      "|25.71|58.59|1012.77|61.83|451.28|[25.71,58.59,1012...| 443.1661810913976|\n",
      "|26.19|69.34|1009.48|87.59|433.99|[26.19,69.34,1009...| 435.4263567111474|\n",
      "|21.42|43.79|1015.76|43.08|462.19|[21.42,43.79,1015...| 458.2610604716974|\n",
      "|18.21| 45.0|1022.86|48.84|467.54|[18.21,45.0,1022....|463.85600228221267|\n",
      "|11.04|41.74| 1022.6|77.51| 477.2|[11.04,41.74,1022...| 474.2498032497976|\n",
      "|14.45|52.75|1023.97|63.59|459.85|[14.45,52.75,1023...| 467.2152077040968|\n",
      "|13.97|38.47|1015.15|55.28| 464.3|[13.97,38.47,1015...|472.27139648674444|\n",
      "+-----+-----+-------+-----+------+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "saved_model.transform(df).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train, df_test = df.randomSplit(weights=[0.7, 0.3], seed = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.563138184940591"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipelineModel = pipeline.fit(df_train)\n",
    "evaluator.evaluate(pipelineModel.transform(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGrid = ParamGridBuilder()\\\n",
    "    .addGrid(lr.regParam, [0.1, 0.01]) \\\n",
    "    .addGrid(lr.fitIntercept, [False, True])\\\n",
    "    .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])\\\n",
    "    .build()\n",
    "\n",
    "# In this case the estimator is simply the linear regression.\n",
    "# A TrainValidationSplit requires an Estimator, a set of Estimator ParamMaps, and an Evaluator.\n",
    "tvs = TrainValidationSplit(estimator=lr,\n",
    "                           estimatorParamMaps=paramGrid,\n",
    "                           evaluator=evaluator,\n",
    "                           trainRatio=0.8)\n",
    "\n",
    "tuned_model = tvs.fit(vectorizer.transform(df_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LinearRegression_4bf49d4e37c6cf84ec09,\n",
       " [5.039347932903683,\n",
       "  5.636217630762049,\n",
       "  5.107247882789134,\n",
       "  4.547646522666319,\n",
       "  4.545696090598205,\n",
       "  4.545352062329218,\n",
       "  5.038546732463139,\n",
       "  5.49137539732243,\n",
       "  5.628475999107409,\n",
       "  4.545755899303294,\n",
       "  4.5455883701354445,\n",
       "  4.545438239526134])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_model.bestModel, tuned_model.validationMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-------+-----+------+--------------------+------------------+\n",
      "|  AT|    V|     AP|   RH|    PE|            features|        prediction|\n",
      "+----+-----+-------+-----+------+--------------------+------------------+\n",
      "|1.81|39.42|1026.92|76.97|490.55|[1.81,39.42,1026....| 492.8349077427656|\n",
      "|1.81|39.42|1026.92|76.97|490.55|[1.81,39.42,1026....| 492.8349077427656|\n",
      "|1.81|39.42|1026.92|76.97|490.55|[1.81,39.42,1026....| 492.8349077427656|\n",
      "|1.81|39.42|1026.92|76.97|490.55|[1.81,39.42,1026....| 492.8349077427656|\n",
      "|2.34|39.42|1028.47|69.68|490.34|[2.34,39.42,1028....|492.94214880761615|\n",
      "|2.58|39.42|1028.68|69.03|488.69|[2.58,39.42,1028....|492.58206703142434|\n",
      "|2.58|39.42|1028.68|69.03|488.69|[2.58,39.42,1028....|492.58206703142434|\n",
      "| 2.8|39.64|1011.01|82.96|482.66|[2.8,39.64,1011.0...| 489.0569119382538|\n",
      "| 2.8|39.64|1011.01|82.96|482.66|[2.8,39.64,1011.0...| 489.0569119382538|\n",
      "|3.21|38.44| 1016.9|86.34|491.35|[3.21,38.44,1016....| 488.4152185498315|\n",
      "|3.21|38.44|1017.11|84.86|492.93|[3.21,38.44,1017....| 488.6394965835994|\n",
      "|3.26|41.31| 996.32|100.0|489.38|[3.26,41.31,996.3...| 484.4525561174197|\n",
      "|3.26|41.31| 996.32|100.0|489.38|[3.26,41.31,996.3...| 484.4525561174197|\n",
      "|3.31|39.42|1024.05|84.31|487.19|[3.31,39.42,1024....| 488.7036922378125|\n",
      "|3.31|39.42|1024.05|84.31|487.19|[3.31,39.42,1024....| 488.7036922378125|\n",
      "|3.38|39.64| 1011.0|81.22|488.92|[3.38,39.64,1011....| 488.1800909364742|\n",
      "|3.38|41.31| 998.79|97.76|489.11|[3.38,41.31,998.7...| 484.6874147567333|\n",
      "|3.38|41.31| 998.79|97.76|489.11|[3.38,41.31,998.7...| 484.6874147567333|\n",
      "| 3.4|39.64| 1011.1|83.43|459.86|[3.4,39.64,1011.1...| 487.8310275292321|\n",
      "| 3.4|39.64| 1011.1|83.43|459.86|[3.4,39.64,1011.1...| 487.8310275292321|\n",
      "+----+-----+-------+-----+------+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_test_pred = tuned_model.transform(vectorizer.transform(df_test))\n",
    "df_test_pred.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.5683171800255895"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate(df_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
