{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Projection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data\n",
    "\n",
    "We will load a user-rating data for which each line is of the form\n",
    "\n",
    "userId,movieId,rating,timestamp\n",
    "\n",
    "with one line of header. \n",
    "\n",
    "The timestamps are useful, but for now we are interested in only userId, movieId and rating. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "ratings = pd.read_csv(\"/Users/debapriyo/Dropbox/data/ml-latest/ratings.csv\")\n",
    "\n",
    "ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a sparse matrix of the ratings\n",
    "\n",
    "Instead of a 2-D array, we will create a sparse matrix. We will use the rows as the items and columns as the users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "ii = np.array([1,2,1,2,4])\n",
    "jj = np.array([1,1,2,3,3])\n",
    "vv = np.array([1,1,2,3,2])\n",
    "\n",
    "R2 = csr_matrix((vv, (ii,jj)))\n",
    "\n",
    "print(R2)\n",
    "print(R2.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "users = ratings[\"userId\"].values.astype(int)\n",
    "movies = ratings[\"movieId\"].values.astype(int)\n",
    "vals = ratings[\"rating\"].values\n",
    "\n",
    "\n",
    "R = csr_matrix((vals,(movies-1,users-1)))\n",
    "\n",
    "print(\"The data has %d items with %d dimensions (users).\" %(R.shape[0], R.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random projection -- estimating the dimensions\n",
    "\n",
    "Let us first estimate how many dimensions we will need for certain error bounds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.random_projection import johnson_lindenstrauss_min_dim\n",
    "from sklearn import random_projection\n",
    "\n",
    "for ep in [0.1, 0.15, 0.2, 0.25, 0.3, 0.4]:\n",
    "    min_dim = johnson_lindenstrauss_min_dim(n_samples=R.shape[0], eps=ep)\n",
    "    print(\"Minimum #of dimensions for epsilon = %f is %d.\" %(ep, min_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing the random projection\n",
    "\n",
    "A GaussianRandomProjection (works with similar arguments) for this data will be hard to compute on this machine. We will compute the sparse random projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Projection with epsilon = 0.1\n",
    "transformer = random_projection.SparseRandomProjection(eps=0.1)\n",
    "RP = transformer.fit_transform(R)\n",
    "print(RP.shape)\n",
    "print(RP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing effectiveness\n",
    "\n",
    "We test the effectiveness of the random projection by computing similarity of items in the original dimension as well as in the reduced dimension.\n",
    "\n",
    "First we select some pairs of items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2000\n",
    "\n",
    "randpairs = np.random.randint(R.shape[0],size=(n,2))\n",
    "print(randpairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing distances\n",
    "\n",
    "Let us define a distance measure between two vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist(v1, v2):\n",
    "    return np.linalg.norm(v1-v2)\n",
    "\n",
    "v1 = np.array([1,1])\n",
    "v2 = np.array([0,1])\n",
    "\n",
    "print(dist(v1,v2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance in the original dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "dist_original = np.zeros(n)\n",
    "i = 0\n",
    "total_time = 0.0\n",
    "for pair in randpairs:\n",
    "    # print(pair[0],pair[1])\n",
    "    tick = time.time()\n",
    "    v1 = R[pair[0]].todense()\n",
    "    v2 = R[pair[1]].todense()\n",
    "    dist_original[i] = dist(v1,v2)\n",
    "    tock = time.time()\n",
    "    total_time = total_time + tock - tick\n",
    "    i = i+1\n",
    "print(\"Total time: \", (total_time) , \" seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance in the reduced dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_reduced = np.zeros(n)\n",
    "i = 0\n",
    "total_time = 0.0\n",
    "for pair in randpairs:\n",
    "    # print(pair[0],pair[1])\n",
    "    tick = time.time()\n",
    "    v1 = RP[pair[0]].todense()\n",
    "    v2 = RP[pair[1]].todense()\n",
    "    dist_reduced[i] = dist(v1,v2)*1\n",
    "    tock = time.time()\n",
    "    total_time = total_time + tock - tick\n",
    "    i = i+1\n",
    "print(\"Total time: \", (total_time) , \" seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How close are we after reducing dimension?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = dist_original - dist_reduced\n",
    "\n",
    "nz = []\n",
    "for i in range(len(error)):\n",
    "    if (dist_original[i] != 0):\n",
    "       nz.append(np.abs(error[i]/dist_original[i]))\n",
    "    \n",
    "nz_error = np.array(nz)\n",
    "    \n",
    "print(\"Mean absolute eps: \", np.mean(nz_error))\n",
    "print(\"Max eps: \", np.max(nz_error))\n",
    "\n",
    "# For how many cases did the distance cross the epsilon\n",
    "indicator = nz_error > 0.1\n",
    "print(sum(indicator)/2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
