{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-29T04:09:46.247473Z",
     "iopub.status.busy": "2021-05-29T04:09:46.247096Z",
     "iopub.status.idle": "2021-05-29T04:09:47.473349Z",
     "shell.execute_reply": "2021-05-29T04:09:47.472494Z",
     "shell.execute_reply.started": "2021-05-29T04:09:46.247396Z"
    },
    "id": "7v8yhijkz9_r"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-29T04:09:49.963633Z",
     "iopub.status.busy": "2021-05-29T04:09:49.963331Z",
     "iopub.status.idle": "2021-05-29T04:09:49.971546Z",
     "shell.execute_reply": "2021-05-29T04:09:49.970627Z",
     "shell.execute_reply.started": "2021-05-29T04:09:49.963604Z"
    },
    "id": "XNZBCSpC0pmY"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 6, kernel_size =5)\n",
    "        self.fc1 = nn.Linear(6*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84 )\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x \n",
    "\n",
    "def convfc():\n",
    "    model_arch = Net()\n",
    "    return model_arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-29T04:09:50.444107Z",
     "iopub.status.busy": "2021-05-29T04:09:50.443827Z",
     "iopub.status.idle": "2021-05-29T04:09:59.037500Z",
     "shell.execute_reply": "2021-05-29T04:09:59.036417Z",
     "shell.execute_reply.started": "2021-05-29T04:09:50.444081Z"
    },
    "id": "s5IRMvLU1CR1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import os\n",
    "import argparse\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.models as models\n",
    "%pip install wandb -q\n",
    "import wandb\n",
    "# import Fadml_Assignment_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-29T04:09:59.042321Z",
     "iopub.status.busy": "2021-05-29T04:09:59.042068Z",
     "iopub.status.idle": "2021-05-29T04:09:59.084761Z",
     "shell.execute_reply": "2021-05-29T04:09:59.083836Z",
     "shell.execute_reply.started": "2021-05-29T04:09:59.042294Z"
    },
    "id": "G690V8GW1rvB"
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "best_acc = 0  # best test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5JQO7_zpvaLk",
    "outputId": "5e5c9265-7632-4fab-f2bf-e646e644a3ae"
   },
   "outputs": [],
   "source": [
    "# wandb.init(project=\"pytorch-CIFAR\",reinit=True)\n",
    "# wandb.watch_called = False # Re-run the model without restarting the runtime, unnecessary after our next release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-29T04:10:02.425510Z",
     "iopub.status.busy": "2021-05-29T04:10:02.425171Z",
     "iopub.status.idle": "2021-05-29T04:10:02.432925Z",
     "shell.execute_reply": "2021-05-29T04:10:02.431967Z",
     "shell.execute_reply.started": "2021-05-29T04:10:02.425479Z"
    },
    "id": "xj4MZeiX3FqD",
    "outputId": "ee01568f-fc7f-433d-922e-bb43e7fb3198"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-29T04:10:02.911579Z",
     "iopub.status.busy": "2021-05-29T04:10:02.911281Z",
     "iopub.status.idle": "2021-05-29T04:10:02.918619Z",
     "shell.execute_reply": "2021-05-29T04:10:02.917648Z",
     "shell.execute_reply.started": "2021-05-29T04:10:02.911551Z"
    },
    "id": "kARCDfSF23bQ",
    "outputId": "a093568f-4afb-4ff3-9f87-1cd5eaf278de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data transformation\n"
     ]
    }
   ],
   "source": [
    "# Data\n",
    "print('Data transformation')\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-29T04:10:04.966444Z",
     "iopub.status.busy": "2021-05-29T04:10:04.966076Z",
     "iopub.status.idle": "2021-05-29T04:10:11.927455Z",
     "shell.execute_reply": "2021-05-29T04:10:11.926623Z",
     "shell.execute_reply.started": "2021-05-29T04:10:04.966416Z"
    },
    "id": "yn-YQRkQ2_n_",
    "outputId": "d17bddeb-68b4-4eb5-b078-349884ef4c59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39440a23d5d04515a2b3f6bccbac4fd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "validation_split = .2\n",
    "shuffle_dataset = True\n",
    "random_seed= 42\n",
    "\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform_train)\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "dataset_size = len(trainset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Creating train and valid sampler\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=128,num_workers=2,sampler=train_sampler)\n",
    "\n",
    "validationloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=128, num_workers=2,sampler=valid_sampler)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-29T04:10:14.217900Z",
     "iopub.status.busy": "2021-05-29T04:10:14.217486Z",
     "iopub.status.idle": "2021-05-29T04:10:14.226466Z",
     "shell.execute_reply": "2021-05-29T04:10:14.225646Z",
     "shell.execute_reply.started": "2021-05-29T04:10:14.217868Z"
    },
    "id": "LzRjEeOUh7X7",
    "outputId": "4f465838-e209-431a-fc61-8efc1aa086ea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7fd56f3e0290>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-29T04:10:14.666054Z",
     "iopub.status.busy": "2021-05-29T04:10:14.665746Z",
     "iopub.status.idle": "2021-05-29T04:10:14.671178Z",
     "shell.execute_reply": "2021-05-29T04:10:14.668666Z",
     "shell.execute_reply.started": "2021-05-29T04:10:14.666025Z"
    },
    "id": "LZQTE91M3Ccb",
    "outputId": "9d4c002c-ab19-4356-c3e5-bf58364bcf93"
   },
   "outputs": [],
   "source": [
    "# #Model\n",
    "# print('Model creation')\n",
    "# net =Net()\n",
    "# net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-29T04:10:24.116223Z",
     "iopub.status.busy": "2021-05-29T04:10:24.115895Z",
     "iopub.status.idle": "2021-05-29T04:10:24.127639Z",
     "shell.execute_reply": "2021-05-29T04:10:24.126590Z",
     "shell.execute_reply.started": "2021-05-29T04:10:24.116193Z"
    },
    "id": "JvVF213n3Kxw"
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "def train(epoch,net,criterion,optimizer):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    net.train()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    val_running_loss = 0.0\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        # Write your code here\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs).to(device)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "    running_loss_history.append(running_loss)\n",
    "    #Write training losses to losstrain.txt for each epoch\n",
    "    ## Creating a dictionary to store the epoch and the losses corresponding to that\n",
    "    losstrain={'epoch': [epoch],'loss':[running_loss]}\n",
    "    ## Making a dataframe from this dictionary\n",
    "    loss_df = pd.DataFrame.from_dict(losstrain)\n",
    "    ## Making a txt file from this dataframe\n",
    "    loss_df.to_csv(r'train_loss.txt', header=None, index=None, sep=' ', mode='a')\n",
    "    print('Finished Training')\n",
    "    print('Training Loss: %d' % running_loss)\n",
    "    wandb.log({\"Epoch\":epoch,\"Training Loss\": running_loss})\n",
    "\n",
    "    with torch.no_grad(): # we do not need gradient for validation.\n",
    "      for val_inputs, val_labels in validationloader:\n",
    "        val_inputs = val_inputs.to(device)\n",
    "        val_labels = val_labels.to(device)\n",
    "        val_outputs = net(val_inputs)\n",
    "        val_loss = criterion(val_outputs, val_labels)\n",
    "        \n",
    "        _, val_preds = torch.max(val_outputs, 1)\n",
    "        val_running_loss += val_loss.item()\n",
    "    val_running_loss_history.append(val_running_loss)\n",
    "    wandb.log({\"Epoch\":epoch,\"Validation Loss\": val_running_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-29T04:10:30.510018Z",
     "iopub.status.busy": "2021-05-29T04:10:30.509666Z",
     "iopub.status.idle": "2021-05-29T04:10:30.520549Z",
     "shell.execute_reply": "2021-05-29T04:10:30.519758Z",
     "shell.execute_reply.started": "2021-05-29T04:10:30.509988Z"
    },
    "id": "8Aq5-COygscR"
   },
   "outputs": [],
   "source": [
    "def test(epoch,net,criterion):\n",
    "  global best_acc\n",
    "  net.eval()\n",
    "  total = 0\n",
    "  correct = 0\n",
    "  test_loss = 0\n",
    "  test_images = []\n",
    "  print('\\nEpoch: %d' % epoch)\n",
    "  with torch.no_grad():\n",
    "      for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "          inputs, targets = inputs.to(device), targets.to(device)\n",
    "          ## Giving input to the model\n",
    "          outputs = net(inputs)\n",
    "          loss = criterion(outputs, targets)\n",
    "          ## Predicting on the input data\n",
    "          _, predicted = torch.max(outputs.data, 1)\n",
    "          ## Defining the total size of the target\n",
    "          total += targets.size(0)\n",
    "          ## Getting the total number of correctly classified labels\n",
    "          test_loss += loss.item()\n",
    "          correct += (predicted == targets).sum().item()\n",
    "          ## Appending images to image list\n",
    "          test_images.append(wandb.Image(inputs[0], caption=\"Pred: {} Truth: {}\".format(predicted[0].item(), targets[0])))\n",
    "          ## Getting the accuracy of the model\n",
    "      model_accuracy = 100 * correct / total\n",
    "      print('Testing Accuracy: %d ' % model_accuracy)\n",
    "      print('\\n')\n",
    "      ## Checking whether the accuracy is better than the best accuracy\n",
    "      if model_accuracy>best_acc:\n",
    "      ## Saving the new value of best_accuracy\n",
    "        best_acc = model_accuracy\n",
    "        ## Saving the model\n",
    "        # Save checkpoint for the model which yields best accuracy\n",
    "        PATH = './cifar_net.pth'\n",
    "        torch.save(net.state_dict(), PATH)\n",
    "          # Write test set losses to losstest.txt for each epoch\n",
    "      df={'epoch': [epoch],'loss':[test_loss]}\n",
    "      data = pd.DataFrame.from_dict(df)\n",
    "      data.to_csv(r'losstest.txt', header=None, index=None, sep=' ', mode='a')\n",
    "      #Write test set accuracies to acctest.txt for each epoch\n",
    "      testaccuracy={'epoch': [epoch],'test_accuracy':[model_accuracy]}\n",
    "      ## Making a dataframe from this dictionary\n",
    "      accuracy_df = pd.DataFrame.from_dict(testaccuracy)\n",
    "      ## Making a txt file from this dataframe\n",
    "      accuracy_df.to_csv(r'test_accuracy.txt', header=None, index=None, sep=' ', mode='a')\n",
    "      wandb.log({\"Epoch\":epoch,\"Testing_images\": test_images,\"Test Accuracy\": 100. * correct / len(testloader.dataset),\"Test Loss\": test_loss})   \n",
    "  # Write test set losses to losstest.txt for each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-29T04:10:59.502570Z",
     "iopub.status.busy": "2021-05-29T04:10:59.502251Z",
     "iopub.status.idle": "2021-05-29T04:10:59.508495Z",
     "shell.execute_reply": "2021-05-29T04:10:59.507367Z",
     "shell.execute_reply.started": "2021-05-29T04:10:59.502540Z"
    },
    "id": "Fh1_cHzNKANv"
   },
   "outputs": [],
   "source": [
    "def training_testing(net,criterion,optimizer):\n",
    "  n_epochs_stop = 20\n",
    "  epochs_no_improve = 0\n",
    "  for epoch in range(0,5):\n",
    "    print(\"Model Training\")\n",
    "    train(epoch,net,criterion,optimizer)\n",
    "    if val_running_loss_history[epoch]>val_running_loss_history[epoch-1]:\n",
    "      if(epochs_no_improve<n_epochs_stop):\n",
    "        epochs_no_improve+=1\n",
    "      else:\n",
    "        break\n",
    "    else:\n",
    "      epochs_no_improve=0\n",
    "    print(\"\\n Model Testing\")\n",
    "    test(epoch,net,criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-29T04:10:38.878290Z",
     "iopub.status.busy": "2021-05-29T04:10:38.877941Z",
     "iopub.status.idle": "2021-05-29T04:10:38.886064Z",
     "shell.execute_reply": "2021-05-29T04:10:38.885081Z",
     "shell.execute_reply.started": "2021-05-29T04:10:38.878260Z"
    },
    "id": "exkYOhgYBHFB"
   },
   "outputs": [],
   "source": [
    "def predict_with_best_param(net):\n",
    "  ## Loading the best model parameters \n",
    "  PATH ='./cifar_net.pth'\n",
    "  net.load_state_dict(torch.load(PATH))\n",
    "  # prepare to count predictions for each class\n",
    "  correct_pred = {classname: 0 for classname in classes}\n",
    "  total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "  # again no gradients needed\n",
    "  with torch.no_grad():\n",
    "      for batch_id, (images, labels) in enumerate(testloader):\n",
    "          images, labels = images.to(device), labels.to(device)\n",
    "          outputs = net(images)\n",
    "          _, predictions = torch.max(outputs, 1)\n",
    "          # collect the correct predictions for each class\n",
    "          for label, prediction in zip(labels, predictions):\n",
    "              if label == prediction:   \n",
    "                  correct_pred[classes[label]] += 1\n",
    "              total_pred[classes[label]] += 1\n",
    "\n",
    "\n",
    "  # print accuracy for each class\n",
    "  for classname, correct_count in correct_pred.items():\n",
    "      accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "      print(\"Accuracy for class {:5s} is: {:.1f} %\".format(classname,\n",
    "                                                    accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-29T04:10:43.061302Z",
     "iopub.status.busy": "2021-05-29T04:10:43.060958Z",
     "iopub.status.idle": "2021-05-29T04:10:43.070164Z",
     "shell.execute_reply": "2021-05-29T04:10:43.068890Z",
     "shell.execute_reply.started": "2021-05-29T04:10:43.061272Z"
    },
    "id": "Xm9eqIxBOPs3"
   },
   "outputs": [],
   "source": [
    "def confusion_matrix_plot(net):\n",
    "  total_correct = 0\n",
    "  total_images = 0\n",
    "  confusion_matrix = np.zeros([10,10], int)\n",
    "  with torch.no_grad():\n",
    "      for batch_id, (images, labels) in enumerate(testloader):\n",
    "          images, labels = images.to(device), labels.to(device)\n",
    "          outputs = net(images)\n",
    "          _, predicted = torch.max(outputs.data, 1)\n",
    "          total_images += labels.size(0)\n",
    "          total_correct += (predicted == labels).sum().item()\n",
    "          for i, l in enumerate(labels):\n",
    "              confusion_matrix[l.item(), predicted[i].item()] += 1 \n",
    "\n",
    "  model_accuracy = total_correct / total_images * 100\n",
    "  print('Model accuracy on {0} test images: {1:.2f}%'.format(total_images, model_accuracy))\n",
    "  fig, ax = plt.subplots(1,1,figsize=(8,6))\n",
    "  sns.heatmap(confusion_matrix,annot = True,fmt='d', cmap=\"mako\")\n",
    "  plt.ylabel('Actual Category')\n",
    "  plt.yticks(range(10), classes)\n",
    "  plt.xlabel('Predicted Category')\n",
    "  plt.xticks(range(10), classes)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-29T04:11:04.644626Z",
     "iopub.status.busy": "2021-05-29T04:11:04.644306Z"
    },
    "id": "1YQpkBkxLce6",
    "outputId": "fbe43241-6ce5-44c7-b99d-0e369d20bfab"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:  ········································\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.31 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.26<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">driven-frost-8</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/vatangl14/pytorch-CIFAR-Vatan_500\" target=\"_blank\">https://wandb.ai/vatangl14/pytorch-CIFAR-Vatan_500</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/vatangl14/pytorch-CIFAR-Vatan_500/runs/3touqu0g\" target=\"_blank\">https://wandb.ai/vatangl14/pytorch-CIFAR-Vatan_500/runs/3touqu0g</a><br/>\n",
       "                Run data is saved locally in <code>/kaggle/working/wandb/run-20210529_041139-3touqu0g</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Training\n",
      "\n",
      "Epoch: 0\n",
      "Finished Training\n",
      "Training Loss: 719\n",
      "\n",
      " Model Testing\n",
      "\n",
      "Epoch: 0\n",
      "Testing Accuracy: 14 \n",
      "\n",
      "\n",
      "Model Training\n",
      "\n",
      "Epoch: 1\n",
      "Finished Training\n",
      "Training Loss: 703\n",
      "\n",
      " Model Testing\n",
      "\n",
      "Epoch: 1\n",
      "Testing Accuracy: 21 \n",
      "\n",
      "\n",
      "Model Training\n",
      "\n",
      "Epoch: 2\n",
      "Finished Training\n",
      "Training Loss: 645\n",
      "\n",
      " Model Testing\n",
      "\n",
      "Epoch: 2\n",
      "Testing Accuracy: 28 \n",
      "\n",
      "\n",
      "Model Training\n",
      "\n",
      "Epoch: 3\n"
     ]
    }
   ],
   "source": [
    "run=wandb.init(project=\"pytorch-CIFAR-Vatan_500\",reinit=True)\n",
    "wandb.watch_called = False # Re-run the model w\n",
    "net1 = convfc()\n",
    "wandb.watch(net1,log=\"all\")\n",
    "net1 = net1.to(device)\n",
    "running_loss_history = []\n",
    "val_running_loss_history = []\n",
    "### Defining a Loss function and optimizer for configuration 1\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net1.parameters(), lr=0.001, momentum=0.9)\n",
    "training_testing(net1,criterion,optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NAU0PZhL7Xz2",
    "outputId": "cf60ab5f-52f3-4036-cd51-394f85ab541c"
   },
   "outputs": [],
   "source": [
    "predict_with_best_param(net1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g0ZC5FBh70Uo",
    "outputId": "0f0454c7-2aba-4716-e221-dee2236fc4e9"
   },
   "outputs": [],
   "source": [
    "confusion_matrix_plot(net1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pkgOgObMEGC7",
    "outputId": "5c56c0eb-dfbe-48d4-da25-a3f4048a4f09"
   },
   "outputs": [],
   "source": [
    "running_loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z4PqJPNdGCdF",
    "outputId": "6e284059-ca7b-4d5c-f710-da381f8c6b52"
   },
   "outputs": [],
   "source": [
    "val_running_loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-29T03:09:29.967596Z",
     "iopub.status.busy": "2021-05-29T03:09:29.967263Z"
    },
    "id": "MeBf37aF_7Fk",
    "outputId": "3424d760-865d-4ee5-a885-6cb23fb0fd43"
   },
   "outputs": [],
   "source": [
    "run=wandb.init(project=\"pytorch-CIFAR-Vatan_500\",reinit=True)\n",
    "wandb.watch_called = False # Re-run the model w\n",
    "net2 = convfc()\n",
    "net2 = net2.to(device)\n",
    "wandb.watch(net2,log=\"all\")\n",
    "running_loss_history = []\n",
    "val_running_loss_history = []\n",
    "### Defining a Loss function and optimizer for configuration 2\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net2.parameters(), lr=0.001)\n",
    "training_testing(net2,criterion,optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JUQE9seJOTO6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T9KnTLF0OTO_",
    "outputId": "823c3183-13cd-49af-fb2f-a6ed1ac2fe96"
   },
   "outputs": [],
   "source": [
    "training_testing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "44CmvJupOzRk"
   },
   "outputs": [],
   "source": [
    "line_eng = open('/content/train_loss.txt',encoding='utf-8').read().strip().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TxOkhUJ0Pa_a",
    "outputId": "82758613-17ef-4eeb-a895-4e60e5ca11a8"
   },
   "outputs": [],
   "source": [
    "line_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rsSkQtkZPcEL",
    "outputId": "8ee51ef9-ae67-4648-f1d5-e86359480f85"
   },
   "outputs": [],
   "source": [
    "## Loading the best model parameters \n",
    "PATH ='./cifar_net.pth'\n",
    "net.load_state_dict(torch.load(PATH))\n",
    "# prepare to count predictions for each class\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "# again no gradients needed\n",
    "with torch.no_grad():\n",
    "    for batch_id, (images, labels) in enumerate(testloader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:   \n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(\"Accuracy for class {:5s} is: {:.1f} %\".format(classname,\n",
    "                                                   accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IJUMMrmLRtNl",
    "outputId": "cc98debc-35ae-41aa-8fc3-d33caf874290"
   },
   "outputs": [],
   "source": [
    "total_correct = 0\n",
    "total_images = 0\n",
    "confusion_matrix = np.zeros([10,10], int)\n",
    "with torch.no_grad():\n",
    "    for batch_id, (images, labels) in enumerate(testloader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_images += labels.size(0)\n",
    "        total_correct += (predicted == labels).sum().item()\n",
    "        for i, l in enumerate(labels):\n",
    "            confusion_matrix[l.item(), predicted[i].item()] += 1 \n",
    "\n",
    "model_accuracy = total_correct / total_images * 100\n",
    "print('Model accuracy on {0} test images: {1:.2f}%'.format(total_images, model_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GjkNnVpyRZqL",
    "outputId": "884b3671-bc7b-4135-be67-5a2da06e6b28"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(8,6))\n",
    "sns.heatmap(confusion_matrix,annot = True,fmt='d')\n",
    "plt.ylabel('Actual Category')\n",
    "plt.yticks(range(10), classes)\n",
    "plt.xlabel('Predicted Category')\n",
    "plt.xticks(range(10), classes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PQSWG-ldRBvt",
    "outputId": "8890ab0d-d7d5-4030-dd84-17d9f10f8d88"
   },
   "outputs": [],
   "source": [
    "correct_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T67Y13FjRbg0",
    "outputId": "f655e30e-68d3-43f3-b277-6f9ecb37a3a8"
   },
   "outputs": [],
   "source": [
    "## Defining a resnet model\n",
    "rn34 = models.resnet34(pretrained=True)\n",
    "rn34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in rn34.parameters():\n",
    "  param.requires_grad = False\n",
    "rn34.fc = nn.Sequential(nn.Linear(512,256),\n",
    "                         nn.ReLU(),\n",
    "                         nn.Linear(256,128),\n",
    "                         nn.ReLU(),\n",
    "                         nn.Linear(128,10),\n",
    "                         nn.Softmax(dim =1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run=wandb.init(project=\"pytorch-CIFAR-Vatan_500\",reinit=True)\n",
    "wandb.watch_called = False # Re-run the model w\n",
    "rn34 = rn34.to(device)\n",
    "wandb.watch(rn34,log=\"all\")\n",
    "running_loss_history = []\n",
    "val_running_loss_history = []\n",
    "### Defining a Loss function and optimizer for configuration 2\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(rn34.parameters(), lr=0.001)\n",
    "training_testing(rn34,criterion,optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mCOTQ5-1ic4O"
   },
   "outputs": [],
   "source": [
    "# ## Getting the penultimate layer output so that we can define our own fc from there\n",
    "# input_to_fc=rn34.fc.in_features\n",
    "# rn34.fc = nn.Linear(input_to_fc, 256)\n",
    "# rn34.fc1 = nn.Linear(256,128)\n",
    "# rn34.fc2 = nn.Linear(128,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3SGZ9YqoX9tF",
    "outputId": "aafeadd0-e210-4418-e7ec-af70fffbe26c"
   },
   "outputs": [],
   "source": [
    "rn34.modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VQ26nD8FU-7A"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(rn34.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P8UiGzx-lohg",
    "outputId": "8df708d8-2b96-4768-bf32-e7a26954f4d6"
   },
   "outputs": [],
   "source": [
    "rn18 = rn18.to(device)\n",
    "running_loss_history = []\n",
    "val_running_loss_history = []\n",
    "training_testing(rn18,criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aOMzX7qrtISf"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
